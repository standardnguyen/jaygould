{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EPUB Preparation Notebook\n",
    "# Run cells in order to prepare your markdown files for EPUB generation\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Setup and Imports\n",
    "\n",
    "# %%\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from typing import Tuple, Optional, List\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML, Markdown\n",
    "\n",
    "# Configuration\n",
    "PARTS_DIR = Path(\"proper_parts\")  # Change this if your files are elsewhere\n",
    "CREATE_BACKUP = True  # Set to False to skip backup\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Helper Functions\n",
    "\n",
    "# %%\n",
    "def extract_chapter_info(filename: str) -> Tuple[Optional[str], Optional[str]]:\n",
    "    \"\"\"Extract file number and chapter number from filename.\"\"\"\n",
    "    # Pattern for image files: 005_chapter_04_img.md\n",
    "    img_match = re.match(r'(\\d{3})_chapter_(\\d+)_img\\.md', filename)\n",
    "    if img_match:\n",
    "        return img_match.group(1), img_match.group(2)\n",
    "\n",
    "    # Pattern for chapter files: 004_chapter_04.md\n",
    "    chapter_match = re.match(r'(\\d{3})_chapter_(\\d+)\\.md', filename)\n",
    "    if chapter_match:\n",
    "        return chapter_match.group(1), chapter_match.group(2)\n",
    "\n",
    "    return None, None\n",
    "\n",
    "\n",
    "def find_corresponding_chapter(img_file: Path, parts_dir: Path) -> Optional[Path]:\n",
    "    \"\"\"Find the chapter file that corresponds to an image file.\"\"\"\n",
    "    img_num, chapter_num = extract_chapter_info(img_file.name)\n",
    "\n",
    "    if not img_num or not chapter_num:\n",
    "        return None\n",
    "\n",
    "    # First try: image number minus 1 (common pattern)\n",
    "    expected_num = str(int(img_num) - 1).zfill(3)\n",
    "    expected_file = parts_dir / f\"{expected_num}_chapter_{chapter_num}.md\"\n",
    "\n",
    "    if expected_file.exists():\n",
    "        return expected_file\n",
    "\n",
    "    # Second try: look for any file with matching chapter number\n",
    "    for file in parts_dir.glob(f\"*_chapter_{chapter_num}.md\"):\n",
    "        if \"_img.md\" not in file.name:\n",
    "            return file\n",
    "\n",
    "    return None\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 1. Analyze Current Files\n",
    "\n",
    "# %%\n",
    "# Check if directory exists\n",
    "if not PARTS_DIR.exists():\n",
    "    display(HTML(f'<div style=\"color: red; font-weight: bold;\">ERROR: Directory {PARTS_DIR} does not exist!</div>'))\n",
    "else:\n",
    "    # List all markdown files\n",
    "    all_files = sorted(list(PARTS_DIR.glob(\"*.md\")))\n",
    "    chapter_files = [f for f in all_files if \"_img.md\" not in f.name]\n",
    "    img_files = [f for f in all_files if \"_img.md\" in f.name]\n",
    "\n",
    "    display(Markdown(f\"### Found {len(all_files)} total files:\"))\n",
    "    display(Markdown(f\"- **{len(chapter_files)}** chapter files\"))\n",
    "    display(Markdown(f\"- **{len(img_files)}** image files\"))\n",
    "\n",
    "    # Show image file mappings\n",
    "    if img_files:\n",
    "        display(Markdown(\"### Image File Mappings:\"))\n",
    "        mappings = []\n",
    "        for img_file in img_files:\n",
    "            chapter = find_corresponding_chapter(img_file, PARTS_DIR)\n",
    "            mappings.append({\n",
    "                \"Image File\": img_file.name,\n",
    "                \"Target Chapter\": chapter.name if chapter else \"NOT FOUND\",\n",
    "                \"Status\": \"✓ Ready\" if chapter else \"✗ No match\"\n",
    "            })\n",
    "\n",
    "        df = pd.DataFrame(mappings)\n",
    "        display(df)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 2. Create Backup\n",
    "\n",
    "# %%\n",
    "if CREATE_BACKUP and PARTS_DIR.exists():\n",
    "    backup_dir = PARTS_DIR.parent / \"proper_parts_backup\"\n",
    "\n",
    "    # Remove existing backup if it exists\n",
    "    if backup_dir.exists():\n",
    "        shutil.rmtree(backup_dir)\n",
    "\n",
    "    # Create new backup\n",
    "    backup_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    # Copy all .md files\n",
    "    copied_files = 0\n",
    "    for md_file in PARTS_DIR.glob(\"*.md\"):\n",
    "        shutil.copy2(md_file, backup_dir / md_file.name)\n",
    "        copied_files += 1\n",
    "\n",
    "    display(Markdown(f\"✓ **Backup created:** {copied_files} files copied to `{backup_dir}`\"))\n",
    "else:\n",
    "    display(Markdown(\"⚠️ **Skipping backup**\"))\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 3. Integrate Image Files\n",
    "\n",
    "# %%\n",
    "def integrate_images():\n",
    "    \"\"\"Integrate image files with their corresponding chapters.\"\"\"\n",
    "    processed_dir = PARTS_DIR / \"processed_img_files\"\n",
    "    processed_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for img_file in img_files:\n",
    "        chapter_file = find_corresponding_chapter(img_file, PARTS_DIR)\n",
    "\n",
    "        if chapter_file:\n",
    "            # Read both files\n",
    "            with open(chapter_file, 'r', encoding='utf-8') as f:\n",
    "                chapter_content = f.read()\n",
    "\n",
    "            with open(img_file, 'r', encoding='utf-8') as f:\n",
    "                img_content = f.read()\n",
    "\n",
    "            # Append image content with newline separator\n",
    "            with open(chapter_file, 'w', encoding='utf-8') as f:\n",
    "                f.write(chapter_content)\n",
    "                if not chapter_content.endswith('\\n'):\n",
    "                    f.write('\\n')\n",
    "                f.write('\\n')  # Extra blank line\n",
    "                f.write(img_content)\n",
    "                if not img_content.endswith('\\n'):\n",
    "                    f.write('\\n')\n",
    "\n",
    "            # Move image file to processed folder\n",
    "            shutil.move(str(img_file), str(processed_dir / img_file.name))\n",
    "\n",
    "            results.append({\n",
    "                \"Image\": img_file.name,\n",
    "                \"Appended to\": chapter_file.name,\n",
    "                \"Status\": \"✓ Success\"\n",
    "            })\n",
    "        else:\n",
    "            results.append({\n",
    "                \"Image\": img_file.name,\n",
    "                \"Appended to\": \"—\",\n",
    "                \"Status\": \"✗ No matching chapter\"\n",
    "            })\n",
    "\n",
    "    return results\n",
    "\n",
    "# Run integration\n",
    "if img_files:\n",
    "    display(Markdown(\"### Integrating images...\"))\n",
    "    results = integrate_images()\n",
    "    display(pd.DataFrame(results))\n",
    "else:\n",
    "    display(Markdown(\"*No image files to integrate*\"))\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 4. Fix Footnotes\n",
    "\n",
    "# %%\n",
    "def fix_footnotes():\n",
    "    \"\"\"Make footnotes globally unique by adding file prefixes.\"\"\"\n",
    "    results = []\n",
    "\n",
    "    # Process all markdown files in the main directory\n",
    "    for md_file in sorted(PARTS_DIR.glob(\"*.md\")):\n",
    "        # Skip if in subdirectory\n",
    "        if md_file.parent != PARTS_DIR:\n",
    "            continue\n",
    "\n",
    "        # Extract file prefix\n",
    "        match = re.match(r'^(\\d{3})_', md_file.name)\n",
    "        if not match:\n",
    "            results.append({\n",
    "                \"File\": md_file.name,\n",
    "                \"Prefix\": \"—\",\n",
    "                \"Status\": \"✗ No prefix found\"\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        prefix = match.group(1)\n",
    "\n",
    "        # Read file content\n",
    "        with open(md_file, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "\n",
    "        # Count footnotes before\n",
    "        footnotes_before = len(re.findall(r'\\[\\^\\d+\\]', content))\n",
    "\n",
    "        # Fix footnote references [^1] -> [^PREFIX_1]\n",
    "        content = re.sub(r'\\[\\^(\\d+)\\]', rf'[^{prefix}_\\1]', content)\n",
    "\n",
    "        # Fix footnote definitions [^1]: -> [^PREFIX_1]:\n",
    "        content = re.sub(r'^\\[\\^(\\d+)\\]:', rf'[^{prefix}_\\1]:', content, flags=re.MULTILINE)\n",
    "\n",
    "        # Write back\n",
    "        with open(md_file, 'w', encoding='utf-8') as f:\n",
    "            f.write(content)\n",
    "\n",
    "        results.append({\n",
    "            \"File\": md_file.name,\n",
    "            \"Prefix\": prefix,\n",
    "            \"Footnotes\": footnotes_before,\n",
    "            \"Status\": \"✓ Fixed\" if footnotes_before > 0 else \"— No footnotes\"\n",
    "        })\n",
    "\n",
    "    return results\n",
    "\n",
    "# Run footnote fixing\n",
    "display(Markdown(\"### Fixing footnotes...\"))\n",
    "footnote_results = fix_footnotes()\n",
    "display(pd.DataFrame(footnote_results))\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 5. Final Report\n",
    "\n",
    "# %%\n",
    "# List final files\n",
    "final_files = sorted([f for f in PARTS_DIR.glob(\"*.md\")])\n",
    "\n",
    "display(Markdown(\"## ✓ Processing Complete!\"))\n",
    "display(Markdown(f\"\"\"\n",
    "- **Backup created in:** `{PARTS_DIR.parent}/proper_parts_backup/`\n",
    "- **Image files moved to:** `{PARTS_DIR}/processed_img_files/`\n",
    "- **Footnotes:** Made globally unique with file prefixes\n",
    "- **Final file count:** {len(final_files)} markdown files\n",
    "\"\"\"))\n",
    "\n",
    "# Show pandoc command\n",
    "display(Markdown(\"### Suggested Pandoc Command:\"))\n",
    "display(Markdown(\"\"\"```bash\n",
    "pandoc -o jay-gould-biography.epub \\\\\n",
    "  --epub-metadata=metadata.xml \\\\\n",
    "  --metadata title=\"Jay Gould: His Business Career 1867-1892\" \\\\\n",
    "  --epub-cover-image=images/cover.png \\\\\n",
    "  --toc --toc-depth=2 \\\\\n",
    "  --split-level=1 \\\\\n",
    "  --standalone \\\\\n",
    "  $(ls proper_parts/???_*.md | sort -V)\n",
    "```\n",
    "\n",
    "**Note:** `--file-scope` is no longer needed!\n",
    "\"\"\"))\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 6. Verification (Optional)\n",
    "\n",
    "# %%\n",
    "# Quick verification of a sample file\n",
    "sample_file = next((f for f in final_files if \"chapter\" in f.name), None)\n",
    "\n",
    "if sample_file:\n",
    "    display(Markdown(f\"### Sample from `{sample_file.name}`:\"))\n",
    "    with open(sample_file, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "\n",
    "    # Show first few lines\n",
    "    lines = content.split('\\n')[:20]\n",
    "    display(Markdown(f\"```markdown\\n{chr(10).join(lines)}\\n...\\n```\"))\n",
    "\n",
    "    # Check for footnotes\n",
    "    footnote_refs = re.findall(r'\\[\\^[^\\]]+\\]', content)\n",
    "    if footnote_refs:\n",
    "        display(Markdown(f\"**Found {len(footnote_refs)} footnote references.** Sample: {', '.join(footnote_refs[:5])}\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
